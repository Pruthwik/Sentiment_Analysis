{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "sentiment_analysis_using_LSTM.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMAAnSWg9mwL",
        "outputId": "b92fe199-33bd-45be-825e-02a3403a8bd5"
      },
      "source": [
        "!pip install ipynb\n",
        "import numpy as np\n",
        "np.random.seed(100)\n",
        "from keras import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Input\n",
        "import spacy\n",
        "import numpy as np\n",
        "from nltk.corpus import movie_reviews\n",
        "from random import shuffle\n",
        "import nltk\n",
        "!python -m spacy download en_core_web_lg\n",
        "import en_core_web_lg\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipynb in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgxuk1vJ9mwQ"
      },
      "source": [
        "# Load a spacy model for english\n",
        "en_model = en_core_web_lg.load()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxQuNLxr9mwS",
        "outputId": "9cc019d9-9860-41f7-b65b-c4b9d901c4c2"
      },
      "source": [
        "for token in en_model('I am taking a lecture on sentiment analysis.'):\n",
        "    print(token, token.pos_, token.lemma_, token.vector.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I PRON -PRON- (300,)\n",
            "am AUX be (300,)\n",
            "taking VERB take (300,)\n",
            "a DET a (300,)\n",
            "lecture NOUN lecture (300,)\n",
            "on ADP on (300,)\n",
            "sentiment NOUN sentiment (300,)\n",
            "analysis NOUN analysis (300,)\n",
            ". PUNCT . (300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p3eOFpD_kCy"
      },
      "source": [
        "def create_data_label_pairs(n=100):\n",
        "    \"\"\"Create data samples and corresponding labels.\"\"\"\n",
        "    postive_file_ids = movie_reviews.fileids(categories=[\"pos\"])[: n]\n",
        "    negative_file_ids = movie_reviews.fileids(categories=[\"neg\"])[: n]\n",
        "    sentence_lengths_pos, sentence_lengths_neg = list(), list()\n",
        "    data_samples, labels = list(), list()\n",
        "    for file_id in postive_file_ids:\n",
        "        print(file_id)\n",
        "        text = movie_reviews.raw(file_id)\n",
        "        sentence_lengths_pos.append(len(nltk.sent_tokenize(text)))\n",
        "        for sent in nltk.sent_tokenize(text):\n",
        "            data_samples.append(sent)\n",
        "            labels.append(\"pos\")\n",
        "    for file_id in negative_file_ids:\n",
        "        print(file_id)\n",
        "        text = movie_reviews.raw(file_id)\n",
        "        sentence_lengths_neg.append(len(nltk.sent_tokenize(text)))\n",
        "        for sent in nltk.sent_tokenize(text):\n",
        "            data_samples.append(sent)\n",
        "            labels.append(\"neg\")\n",
        "    print('Avg Length for POS Samples =', np.mean(sentence_lengths_pos))\n",
        "    print('Avg Length for NEG Samples =', np.mean(sentence_lengths_neg))\n",
        "    print('Avg Length for All Samples =', np.mean(sentence_lengths_pos + sentence_lengths_neg))\n",
        "    return data_samples, labels"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2dLjSO0Ah8T"
      },
      "source": [
        "def shuffle_items(items):\n",
        "    \"\"\"Shuffle items in a list.\"\"\"\n",
        "    shuffle(items)\n",
        "    return items"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw8iZKa_AkBG"
      },
      "source": [
        "def select_items_based_on_indexes(items, indexes):\n",
        "    \"\"\"Select items in a list on specified indexes.\"\"\"\n",
        "    return [items[index] for index in indexes]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5z-_9iy_u5q",
        "outputId": "a8d41034-4e2b-4e37-c59f-d803adca3763"
      },
      "source": [
        "# create new samples of data\n",
        "data_samples, labels = create_data_label_pairs(100)\n",
        "all_indexes = list(range(len(data_samples)))\n",
        "shuffle_items(all_indexes)\n",
        "data_samples = select_items_based_on_indexes(data_samples, all_indexes)\n",
        "labels = select_items_based_on_indexes(labels, all_indexes)\n",
        "# Split train and test data\n",
        "split_point = int(0.8 * len(data_samples))\n",
        "print(split_point)\n",
        "train_data, train_labels = data_samples[: split_point], labels[: split_point]\n",
        "test_data, test_labels = data_samples[split_point:], labels[split_point:]\n",
        "print(len(test_data))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos/cv000_29590.txt\n",
            "pos/cv001_18431.txt\n",
            "pos/cv002_15918.txt\n",
            "pos/cv003_11664.txt\n",
            "pos/cv004_11636.txt\n",
            "pos/cv005_29443.txt\n",
            "pos/cv006_15448.txt\n",
            "pos/cv007_4968.txt\n",
            "pos/cv008_29435.txt\n",
            "pos/cv009_29592.txt\n",
            "pos/cv010_29198.txt\n",
            "pos/cv011_12166.txt\n",
            "pos/cv012_29576.txt\n",
            "pos/cv013_10159.txt\n",
            "pos/cv014_13924.txt\n",
            "pos/cv015_29439.txt\n",
            "pos/cv016_4659.txt\n",
            "pos/cv017_22464.txt\n",
            "pos/cv018_20137.txt\n",
            "pos/cv019_14482.txt\n",
            "pos/cv020_8825.txt\n",
            "pos/cv021_15838.txt\n",
            "pos/cv022_12864.txt\n",
            "pos/cv023_12672.txt\n",
            "pos/cv024_6778.txt\n",
            "pos/cv025_3108.txt\n",
            "pos/cv026_29325.txt\n",
            "pos/cv027_25219.txt\n",
            "pos/cv028_26746.txt\n",
            "pos/cv029_18643.txt\n",
            "pos/cv030_21593.txt\n",
            "pos/cv031_18452.txt\n",
            "pos/cv032_22550.txt\n",
            "pos/cv033_24444.txt\n",
            "pos/cv034_29647.txt\n",
            "pos/cv035_3954.txt\n",
            "pos/cv036_16831.txt\n",
            "pos/cv037_18510.txt\n",
            "pos/cv038_9749.txt\n",
            "pos/cv039_6170.txt\n",
            "pos/cv040_8276.txt\n",
            "pos/cv041_21113.txt\n",
            "pos/cv042_10982.txt\n",
            "pos/cv043_15013.txt\n",
            "pos/cv044_16969.txt\n",
            "pos/cv045_23923.txt\n",
            "pos/cv046_10188.txt\n",
            "pos/cv047_1754.txt\n",
            "pos/cv048_16828.txt\n",
            "pos/cv049_20471.txt\n",
            "pos/cv050_11175.txt\n",
            "pos/cv051_10306.txt\n",
            "pos/cv052_29378.txt\n",
            "pos/cv053_21822.txt\n",
            "pos/cv054_4230.txt\n",
            "pos/cv055_8338.txt\n",
            "pos/cv056_13133.txt\n",
            "pos/cv057_7453.txt\n",
            "pos/cv058_8025.txt\n",
            "pos/cv059_28885.txt\n",
            "pos/cv060_10844.txt\n",
            "pos/cv061_8837.txt\n",
            "pos/cv062_23115.txt\n",
            "pos/cv063_28997.txt\n",
            "pos/cv064_24576.txt\n",
            "pos/cv065_15248.txt\n",
            "pos/cv066_10821.txt\n",
            "pos/cv067_19774.txt\n",
            "pos/cv068_13400.txt\n",
            "pos/cv069_10801.txt\n",
            "pos/cv070_12289.txt\n",
            "pos/cv071_12095.txt\n",
            "pos/cv072_6169.txt\n",
            "pos/cv073_21785.txt\n",
            "pos/cv074_6875.txt\n",
            "pos/cv075_6500.txt\n",
            "pos/cv076_24945.txt\n",
            "pos/cv077_22138.txt\n",
            "pos/cv078_14730.txt\n",
            "pos/cv079_11933.txt\n",
            "pos/cv080_13465.txt\n",
            "pos/cv081_16582.txt\n",
            "pos/cv082_11080.txt\n",
            "pos/cv083_24234.txt\n",
            "pos/cv084_13566.txt\n",
            "pos/cv085_1381.txt\n",
            "pos/cv086_18371.txt\n",
            "pos/cv087_1989.txt\n",
            "pos/cv088_24113.txt\n",
            "pos/cv089_11418.txt\n",
            "pos/cv090_0042.txt\n",
            "pos/cv091_7400.txt\n",
            "pos/cv092_28017.txt\n",
            "pos/cv093_13951.txt\n",
            "pos/cv094_27889.txt\n",
            "pos/cv095_28892.txt\n",
            "pos/cv096_11474.txt\n",
            "pos/cv097_24970.txt\n",
            "pos/cv098_15435.txt\n",
            "pos/cv099_10534.txt\n",
            "neg/cv000_29416.txt\n",
            "neg/cv001_19502.txt\n",
            "neg/cv002_17424.txt\n",
            "neg/cv003_12683.txt\n",
            "neg/cv004_12641.txt\n",
            "neg/cv005_29357.txt\n",
            "neg/cv006_17022.txt\n",
            "neg/cv007_4992.txt\n",
            "neg/cv008_29326.txt\n",
            "neg/cv009_29417.txt\n",
            "neg/cv010_29063.txt\n",
            "neg/cv011_13044.txt\n",
            "neg/cv012_29411.txt\n",
            "neg/cv013_10494.txt\n",
            "neg/cv014_15600.txt\n",
            "neg/cv015_29356.txt\n",
            "neg/cv016_4348.txt\n",
            "neg/cv017_23487.txt\n",
            "neg/cv018_21672.txt\n",
            "neg/cv019_16117.txt\n",
            "neg/cv020_9234.txt\n",
            "neg/cv021_17313.txt\n",
            "neg/cv022_14227.txt\n",
            "neg/cv023_13847.txt\n",
            "neg/cv024_7033.txt\n",
            "neg/cv025_29825.txt\n",
            "neg/cv026_29229.txt\n",
            "neg/cv027_26270.txt\n",
            "neg/cv028_26964.txt\n",
            "neg/cv029_19943.txt\n",
            "neg/cv030_22893.txt\n",
            "neg/cv031_19540.txt\n",
            "neg/cv032_23718.txt\n",
            "neg/cv033_25680.txt\n",
            "neg/cv034_29446.txt\n",
            "neg/cv035_3343.txt\n",
            "neg/cv036_18385.txt\n",
            "neg/cv037_19798.txt\n",
            "neg/cv038_9781.txt\n",
            "neg/cv039_5963.txt\n",
            "neg/cv040_8829.txt\n",
            "neg/cv041_22364.txt\n",
            "neg/cv042_11927.txt\n",
            "neg/cv043_16808.txt\n",
            "neg/cv044_18429.txt\n",
            "neg/cv045_25077.txt\n",
            "neg/cv046_10613.txt\n",
            "neg/cv047_18725.txt\n",
            "neg/cv048_18380.txt\n",
            "neg/cv049_21917.txt\n",
            "neg/cv050_12128.txt\n",
            "neg/cv051_10751.txt\n",
            "neg/cv052_29318.txt\n",
            "neg/cv053_23117.txt\n",
            "neg/cv054_4101.txt\n",
            "neg/cv055_8926.txt\n",
            "neg/cv056_14663.txt\n",
            "neg/cv057_7962.txt\n",
            "neg/cv058_8469.txt\n",
            "neg/cv059_28723.txt\n",
            "neg/cv060_11754.txt\n",
            "neg/cv061_9321.txt\n",
            "neg/cv062_24556.txt\n",
            "neg/cv063_28852.txt\n",
            "neg/cv064_25842.txt\n",
            "neg/cv065_16909.txt\n",
            "neg/cv066_11668.txt\n",
            "neg/cv067_21192.txt\n",
            "neg/cv068_14810.txt\n",
            "neg/cv069_11613.txt\n",
            "neg/cv070_13249.txt\n",
            "neg/cv071_12969.txt\n",
            "neg/cv072_5928.txt\n",
            "neg/cv073_23039.txt\n",
            "neg/cv074_7188.txt\n",
            "neg/cv075_6250.txt\n",
            "neg/cv076_26009.txt\n",
            "neg/cv077_23172.txt\n",
            "neg/cv078_16506.txt\n",
            "neg/cv079_12766.txt\n",
            "neg/cv080_14899.txt\n",
            "neg/cv081_18241.txt\n",
            "neg/cv082_11979.txt\n",
            "neg/cv083_25491.txt\n",
            "neg/cv084_15183.txt\n",
            "neg/cv085_15286.txt\n",
            "neg/cv086_19488.txt\n",
            "neg/cv087_2145.txt\n",
            "neg/cv088_25274.txt\n",
            "neg/cv089_12222.txt\n",
            "neg/cv090_0049.txt\n",
            "neg/cv091_7899.txt\n",
            "neg/cv092_27987.txt\n",
            "neg/cv093_15606.txt\n",
            "neg/cv094_27868.txt\n",
            "neg/cv095_28730.txt\n",
            "neg/cv096_12262.txt\n",
            "neg/cv097_26081.txt\n",
            "neg/cv098_17021.txt\n",
            "neg/cv099_11189.txt\n",
            "Avg Length for POS Samples = 34.74\n",
            "Avg Length for NEG Samples = 34.88\n",
            "Avg Length for All Samples = 34.81\n",
            "5569\n",
            "1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb3Kdhzk9mwX"
      },
      "source": [
        "index_to_label_dict = {0: \"neg\", 1: \"pos\"}\n",
        "label_to_index_dict = {\"neg\": 0, \"pos\": 1}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g0-FSjd9mwY"
      },
      "source": [
        "def create_sentence_vectors(sentences, maxlen=50):\n",
        "    \"\"\"Create sentence vector for each sentence.\"\"\"\n",
        "    sentence_vectors = list()\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        parsed = en_model(sentence)\n",
        "        temp_vector = list()\n",
        "        for token in parsed:\n",
        "            temp_vector.append(token.vector.tolist())\n",
        "        sentence_vectors.append(temp_vector)\n",
        "    return pad_sequences(sentence_vectors, maxlen=maxlen, padding='post')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv8PXG4l9mwZ",
        "outputId": "7e4aaf93-785c-4b4f-f858-3ace28b6ed99"
      },
      "source": [
        "# maximum sentence length is assumed = 50\n",
        "train_sentence_vectors = create_sentence_vectors(train_data, 50)\n",
        "print(len(train_data))\n",
        "print(train_sentence_vectors.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5569\n",
            "(5569, 50, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX4jGIz79mwZ",
        "outputId": "845bd5f2-2686-48c4-98ea-1af3fb43ecb0"
      },
      "source": [
        "train_labels_indexed = np.array([label_to_index_dict[label] for label in train_labels])\n",
        "train_labels_indexed = train_labels_indexed.reshape((train_labels_indexed.shape[0], -1))\n",
        "print(train_labels_indexed.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5569, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2nfY7GdBJ8d",
        "outputId": "762d0f56-2572-454e-8cbd-4ac435a7ee55"
      },
      "source": [
        "# Define a model and train\n",
        "input_layer = Input(shape=(50, 300), name='input')\n",
        "lstm_layer = LSTM(300, name='lstm')(input_layer)\n",
        "output_layer = Dense(2, activation='softmax', name='output')(lstm_layer)\n",
        "model = Model(input_layer, output_layer)\n",
        "print(model.summary())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 50, 300)]         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 300)               721200    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 2)                 602       \n",
            "=================================================================\n",
            "Total params: 721,802\n",
            "Trainable params: 721,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiG8QpolBp7_"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoeodtGDDCGo",
        "outputId": "0d80161b-3f61-4c54-9103-46290c4fe428"
      },
      "source": [
        "# Train on the data\n",
        "train_labels_indexed = train_labels_indexed.reshape((train_labels_indexed.shape[0], 1))\n",
        "model.fit(train_sentence_vectors, train_labels_indexed, batch_size=8, epochs=15)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "697/697 [==============================] - 102s 146ms/step - loss: 0.6853 - accuracy: 0.5091\n",
            "Epoch 2/15\n",
            "697/697 [==============================] - 98s 141ms/step - loss: 0.6827 - accuracy: 0.5209\n",
            "Epoch 3/15\n",
            "697/697 [==============================] - 99s 142ms/step - loss: 0.6741 - accuracy: 0.5288\n",
            "Epoch 4/15\n",
            "697/697 [==============================] - 100s 143ms/step - loss: 0.6686 - accuracy: 0.5347\n",
            "Epoch 5/15\n",
            "697/697 [==============================] - 101s 145ms/step - loss: 0.6650 - accuracy: 0.5572\n",
            "Epoch 6/15\n",
            "697/697 [==============================] - 101s 145ms/step - loss: 0.6587 - accuracy: 0.5644\n",
            "Epoch 7/15\n",
            "697/697 [==============================] - 100s 143ms/step - loss: 0.6444 - accuracy: 0.6050\n",
            "Epoch 8/15\n",
            "697/697 [==============================] - 99s 142ms/step - loss: 0.6308 - accuracy: 0.6157\n",
            "Epoch 9/15\n",
            "697/697 [==============================] - 99s 141ms/step - loss: 0.6299 - accuracy: 0.5947\n",
            "Epoch 10/15\n",
            "697/697 [==============================] - 98s 140ms/step - loss: 0.6132 - accuracy: 0.6236\n",
            "Epoch 11/15\n",
            "697/697 [==============================] - 99s 142ms/step - loss: 0.6135 - accuracy: 0.6102\n",
            "Epoch 12/15\n",
            "697/697 [==============================] - 99s 142ms/step - loss: 0.5831 - accuracy: 0.6585\n",
            "Epoch 13/15\n",
            "697/697 [==============================] - 98s 141ms/step - loss: 0.5689 - accuracy: 0.6797\n",
            "Epoch 14/15\n",
            "697/697 [==============================] - 98s 141ms/step - loss: 0.5515 - accuracy: 0.6908\n",
            "Epoch 15/15\n",
            "697/697 [==============================] - 98s 140ms/step - loss: 0.5353 - accuracy: 0.6983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f12eb3bda50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTQOuvGYDO1_",
        "outputId": "c6a37207-12c0-4f7b-e55c-670565526074"
      },
      "source": [
        "# predict on test data\n",
        "test_sentence_vectors = create_sentence_vectors(test_data, 50)\n",
        "predicted_sentiment_vectors = model.predict(test_sentence_vectors)\n",
        "print(predicted_sentiment_vectors.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1393, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXtBtINFGXoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e6a440-e186-4734-9c4f-468d556478a1"
      },
      "source": [
        "# Evaluation\n",
        "predicted_sentiments = list()\n",
        "for pred in predicted_sentiment_vectors:\n",
        "  predicted_sentiments.append(index_to_label_dict[np.argmax(pred)])\n",
        "print(classification_report(test_labels, predicted_sentiments))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.57      0.76      0.66       700\n",
            "         pos       0.64      0.43      0.51       693\n",
            "\n",
            "    accuracy                           0.60      1393\n",
            "   macro avg       0.61      0.60      0.58      1393\n",
            "weighted avg       0.61      0.60      0.58      1393\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}