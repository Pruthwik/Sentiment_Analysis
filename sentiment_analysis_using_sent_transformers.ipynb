{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "sentiment_analysis_using_sent_transformers.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMAAnSWg9mwL",
        "outputId": "fa2bcc7f-8d78-416c-98aa-1007fe7b236e"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(100)\n",
        "from keras import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Input\n",
        "import spacy\n",
        "import numpy as np\n",
        "from nltk.corpus import movie_reviews\n",
        "from random import shuffle\n",
        "import nltk\n",
        "!python -m spacy download en_core_web_lg\n",
        "!pip install sentence-transformers\n",
        "import en_core_web_lg\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.1)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp37-none-any.whl size=829180945 sha256=d0be9057fdcdec44a581b898adf9c5f5514b02e5b4aab1f195b7aebca7c37406\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mpd0_rfw/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/fd/8a81047bbd9fa134a3f27e12937d2a487bd49d353a038916a5d7ed4e5543/sentence-transformers-2.0.0.tar.gz (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.9MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 20.8MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading https://files.pythonhosted.org/packages/35/03/071adc023c0a7e540cf4652fa9cad13ab32e6ae469bf0cc0262045244812/huggingface_hub-0.0.13-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.6.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 36.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.0.0-cp37-none-any.whl size=126711 sha256=67c4e50be00d2264b124e1363b473ed4a385242d47e3b72b1bffc964de8f9fdc\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/d2/98/d191289a877a34c68aa67e05179521e060f96394a3e9336be6\n",
            "Successfully built sentence-transformers\n",
            "\u001b[31mERROR: transformers 4.8.2 has requirement huggingface-hub==0.0.12, but you'll have huggingface-hub 0.0.13 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.0.13 sacremoses-0.0.45 sentence-transformers-2.0.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.8.2\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgxuk1vJ9mwQ"
      },
      "source": [
        "# Load a spacy model for english\n",
        "en_model = en_core_web_lg.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgShlbNySoo2"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sent_embed_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4FG_SznSzAb",
        "outputId": "512b4862-9e1e-4d6b-a5d5-93acbfc33af9"
      },
      "source": [
        "# check the sentence embedding from the transformers\n",
        "sentence = \"I am home.\"\n",
        "sent_embedding = sent_embed_model.encode(sentence)\n",
        "print(sent_embedding.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(384,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxQuNLxr9mwS",
        "outputId": "9cc019d9-9860-41f7-b65b-c4b9d901c4c2"
      },
      "source": [
        "for token in en_model('I am taking a lecture on sentiment analysis.'):\n",
        "    print(token, token.pos_, token.lemma_, token.vector.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I PRON -PRON- (300,)\n",
            "am AUX be (300,)\n",
            "taking VERB take (300,)\n",
            "a DET a (300,)\n",
            "lecture NOUN lecture (300,)\n",
            "on ADP on (300,)\n",
            "sentiment NOUN sentiment (300,)\n",
            "analysis NOUN analysis (300,)\n",
            ". PUNCT . (300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p3eOFpD_kCy"
      },
      "source": [
        "def create_data_label_pairs(n=100):\n",
        "    \"\"\"Create data samples and corresponding labels.\"\"\"\n",
        "    postive_file_ids = movie_reviews.fileids(categories=[\"pos\"])[: n]\n",
        "    negative_file_ids = movie_reviews.fileids(categories=[\"neg\"])[: n]\n",
        "    sentence_lengths_pos, sentence_lengths_neg = list(), list()\n",
        "    data_samples, labels = list(), list()\n",
        "    for file_id in postive_file_ids:\n",
        "        print(file_id)\n",
        "        text = movie_reviews.raw(file_id)\n",
        "        sentence_lengths_pos.append(len(nltk.sent_tokenize(text)))\n",
        "        for sent in nltk.sent_tokenize(text):\n",
        "            data_samples.append(sent)\n",
        "            labels.append(\"pos\")\n",
        "    for file_id in negative_file_ids:\n",
        "        print(file_id)\n",
        "        text = movie_reviews.raw(file_id)\n",
        "        sentence_lengths_neg.append(len(nltk.sent_tokenize(text)))\n",
        "        for sent in nltk.sent_tokenize(text):\n",
        "            data_samples.append(sent)\n",
        "            labels.append(\"neg\")\n",
        "    print('Avg Length for POS Samples =', np.mean(sentence_lengths_pos))\n",
        "    print('Avg Length for NEG Samples =', np.mean(sentence_lengths_neg))\n",
        "    print('Avg Length for All Samples =', np.mean(sentence_lengths_pos + sentence_lengths_neg))\n",
        "    return data_samples, labels"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2dLjSO0Ah8T"
      },
      "source": [
        "def shuffle_items(items):\n",
        "    \"\"\"Shuffle items in a list.\"\"\"\n",
        "    shuffle(items)\n",
        "    return items"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw8iZKa_AkBG"
      },
      "source": [
        "def select_items_based_on_indexes(items, indexes):\n",
        "    \"\"\"Select items in a list on specified indexes.\"\"\"\n",
        "    return [items[index] for index in indexes]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5z-_9iy_u5q",
        "outputId": "e24f4d3c-e27a-488a-ca32-72ff3b2db964"
      },
      "source": [
        "# create new samples of data\n",
        "data_samples, labels = create_data_label_pairs(100)\n",
        "all_indexes = list(range(len(data_samples)))\n",
        "shuffle_items(all_indexes)\n",
        "data_samples = select_items_based_on_indexes(data_samples, all_indexes)\n",
        "labels = select_items_based_on_indexes(labels, all_indexes)\n",
        "# Split train and test data\n",
        "split_point = int(0.8 * len(data_samples))\n",
        "print(split_point)\n",
        "train_data, train_labels = data_samples[: split_point], labels[: split_point]\n",
        "test_data, test_labels = data_samples[split_point:], labels[split_point:]\n",
        "print(len(test_data))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos/cv000_29590.txt\n",
            "pos/cv001_18431.txt\n",
            "pos/cv002_15918.txt\n",
            "pos/cv003_11664.txt\n",
            "pos/cv004_11636.txt\n",
            "pos/cv005_29443.txt\n",
            "pos/cv006_15448.txt\n",
            "pos/cv007_4968.txt\n",
            "pos/cv008_29435.txt\n",
            "pos/cv009_29592.txt\n",
            "pos/cv010_29198.txt\n",
            "pos/cv011_12166.txt\n",
            "pos/cv012_29576.txt\n",
            "pos/cv013_10159.txt\n",
            "pos/cv014_13924.txt\n",
            "pos/cv015_29439.txt\n",
            "pos/cv016_4659.txt\n",
            "pos/cv017_22464.txt\n",
            "pos/cv018_20137.txt\n",
            "pos/cv019_14482.txt\n",
            "pos/cv020_8825.txt\n",
            "pos/cv021_15838.txt\n",
            "pos/cv022_12864.txt\n",
            "pos/cv023_12672.txt\n",
            "pos/cv024_6778.txt\n",
            "pos/cv025_3108.txt\n",
            "pos/cv026_29325.txt\n",
            "pos/cv027_25219.txt\n",
            "pos/cv028_26746.txt\n",
            "pos/cv029_18643.txt\n",
            "pos/cv030_21593.txt\n",
            "pos/cv031_18452.txt\n",
            "pos/cv032_22550.txt\n",
            "pos/cv033_24444.txt\n",
            "pos/cv034_29647.txt\n",
            "pos/cv035_3954.txt\n",
            "pos/cv036_16831.txt\n",
            "pos/cv037_18510.txt\n",
            "pos/cv038_9749.txt\n",
            "pos/cv039_6170.txt\n",
            "pos/cv040_8276.txt\n",
            "pos/cv041_21113.txt\n",
            "pos/cv042_10982.txt\n",
            "pos/cv043_15013.txt\n",
            "pos/cv044_16969.txt\n",
            "pos/cv045_23923.txt\n",
            "pos/cv046_10188.txt\n",
            "pos/cv047_1754.txt\n",
            "pos/cv048_16828.txt\n",
            "pos/cv049_20471.txt\n",
            "pos/cv050_11175.txt\n",
            "pos/cv051_10306.txt\n",
            "pos/cv052_29378.txt\n",
            "pos/cv053_21822.txt\n",
            "pos/cv054_4230.txt\n",
            "pos/cv055_8338.txt\n",
            "pos/cv056_13133.txt\n",
            "pos/cv057_7453.txt\n",
            "pos/cv058_8025.txt\n",
            "pos/cv059_28885.txt\n",
            "pos/cv060_10844.txt\n",
            "pos/cv061_8837.txt\n",
            "pos/cv062_23115.txt\n",
            "pos/cv063_28997.txt\n",
            "pos/cv064_24576.txt\n",
            "pos/cv065_15248.txt\n",
            "pos/cv066_10821.txt\n",
            "pos/cv067_19774.txt\n",
            "pos/cv068_13400.txt\n",
            "pos/cv069_10801.txt\n",
            "pos/cv070_12289.txt\n",
            "pos/cv071_12095.txt\n",
            "pos/cv072_6169.txt\n",
            "pos/cv073_21785.txt\n",
            "pos/cv074_6875.txt\n",
            "pos/cv075_6500.txt\n",
            "pos/cv076_24945.txt\n",
            "pos/cv077_22138.txt\n",
            "pos/cv078_14730.txt\n",
            "pos/cv079_11933.txt\n",
            "pos/cv080_13465.txt\n",
            "pos/cv081_16582.txt\n",
            "pos/cv082_11080.txt\n",
            "pos/cv083_24234.txt\n",
            "pos/cv084_13566.txt\n",
            "pos/cv085_1381.txt\n",
            "pos/cv086_18371.txt\n",
            "pos/cv087_1989.txt\n",
            "pos/cv088_24113.txt\n",
            "pos/cv089_11418.txt\n",
            "pos/cv090_0042.txt\n",
            "pos/cv091_7400.txt\n",
            "pos/cv092_28017.txt\n",
            "pos/cv093_13951.txt\n",
            "pos/cv094_27889.txt\n",
            "pos/cv095_28892.txt\n",
            "pos/cv096_11474.txt\n",
            "pos/cv097_24970.txt\n",
            "pos/cv098_15435.txt\n",
            "pos/cv099_10534.txt\n",
            "neg/cv000_29416.txt\n",
            "neg/cv001_19502.txt\n",
            "neg/cv002_17424.txt\n",
            "neg/cv003_12683.txt\n",
            "neg/cv004_12641.txt\n",
            "neg/cv005_29357.txt\n",
            "neg/cv006_17022.txt\n",
            "neg/cv007_4992.txt\n",
            "neg/cv008_29326.txt\n",
            "neg/cv009_29417.txt\n",
            "neg/cv010_29063.txt\n",
            "neg/cv011_13044.txt\n",
            "neg/cv012_29411.txt\n",
            "neg/cv013_10494.txt\n",
            "neg/cv014_15600.txt\n",
            "neg/cv015_29356.txt\n",
            "neg/cv016_4348.txt\n",
            "neg/cv017_23487.txt\n",
            "neg/cv018_21672.txt\n",
            "neg/cv019_16117.txt\n",
            "neg/cv020_9234.txt\n",
            "neg/cv021_17313.txt\n",
            "neg/cv022_14227.txt\n",
            "neg/cv023_13847.txt\n",
            "neg/cv024_7033.txt\n",
            "neg/cv025_29825.txt\n",
            "neg/cv026_29229.txt\n",
            "neg/cv027_26270.txt\n",
            "neg/cv028_26964.txt\n",
            "neg/cv029_19943.txt\n",
            "neg/cv030_22893.txt\n",
            "neg/cv031_19540.txt\n",
            "neg/cv032_23718.txt\n",
            "neg/cv033_25680.txt\n",
            "neg/cv034_29446.txt\n",
            "neg/cv035_3343.txt\n",
            "neg/cv036_18385.txt\n",
            "neg/cv037_19798.txt\n",
            "neg/cv038_9781.txt\n",
            "neg/cv039_5963.txt\n",
            "neg/cv040_8829.txt\n",
            "neg/cv041_22364.txt\n",
            "neg/cv042_11927.txt\n",
            "neg/cv043_16808.txt\n",
            "neg/cv044_18429.txt\n",
            "neg/cv045_25077.txt\n",
            "neg/cv046_10613.txt\n",
            "neg/cv047_18725.txt\n",
            "neg/cv048_18380.txt\n",
            "neg/cv049_21917.txt\n",
            "neg/cv050_12128.txt\n",
            "neg/cv051_10751.txt\n",
            "neg/cv052_29318.txt\n",
            "neg/cv053_23117.txt\n",
            "neg/cv054_4101.txt\n",
            "neg/cv055_8926.txt\n",
            "neg/cv056_14663.txt\n",
            "neg/cv057_7962.txt\n",
            "neg/cv058_8469.txt\n",
            "neg/cv059_28723.txt\n",
            "neg/cv060_11754.txt\n",
            "neg/cv061_9321.txt\n",
            "neg/cv062_24556.txt\n",
            "neg/cv063_28852.txt\n",
            "neg/cv064_25842.txt\n",
            "neg/cv065_16909.txt\n",
            "neg/cv066_11668.txt\n",
            "neg/cv067_21192.txt\n",
            "neg/cv068_14810.txt\n",
            "neg/cv069_11613.txt\n",
            "neg/cv070_13249.txt\n",
            "neg/cv071_12969.txt\n",
            "neg/cv072_5928.txt\n",
            "neg/cv073_23039.txt\n",
            "neg/cv074_7188.txt\n",
            "neg/cv075_6250.txt\n",
            "neg/cv076_26009.txt\n",
            "neg/cv077_23172.txt\n",
            "neg/cv078_16506.txt\n",
            "neg/cv079_12766.txt\n",
            "neg/cv080_14899.txt\n",
            "neg/cv081_18241.txt\n",
            "neg/cv082_11979.txt\n",
            "neg/cv083_25491.txt\n",
            "neg/cv084_15183.txt\n",
            "neg/cv085_15286.txt\n",
            "neg/cv086_19488.txt\n",
            "neg/cv087_2145.txt\n",
            "neg/cv088_25274.txt\n",
            "neg/cv089_12222.txt\n",
            "neg/cv090_0049.txt\n",
            "neg/cv091_7899.txt\n",
            "neg/cv092_27987.txt\n",
            "neg/cv093_15606.txt\n",
            "neg/cv094_27868.txt\n",
            "neg/cv095_28730.txt\n",
            "neg/cv096_12262.txt\n",
            "neg/cv097_26081.txt\n",
            "neg/cv098_17021.txt\n",
            "neg/cv099_11189.txt\n",
            "Avg Length for POS Samples = 34.74\n",
            "Avg Length for NEG Samples = 34.88\n",
            "Avg Length for All Samples = 34.81\n",
            "5569\n",
            "1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb3Kdhzk9mwX"
      },
      "source": [
        "index_to_label_dict = {0: \"neg\", 1: \"pos\"}\n",
        "label_to_index_dict = {\"neg\": 0, \"pos\": 1}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g0-FSjd9mwY"
      },
      "source": [
        "def create_sentence_vectors(sentences, model):\n",
        "    \"\"\"Create sentence vector for each sentence using the model.\"\"\"\n",
        "    return model.encode(sentences)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv8PXG4l9mwZ",
        "outputId": "52004fe8-3c7a-4ab9-8aa6-fe8fe3aee14d"
      },
      "source": [
        "# Find the sentence vectors for the training data\n",
        "train_sentence_vectors = create_sentence_vectors(train_data, sent_embed_model)\n",
        "print(train_sentence_vectors.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5569, 384)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX4jGIz79mwZ",
        "outputId": "ec4b8469-1bef-431e-8a18-9222fa287dca"
      },
      "source": [
        "train_labels_indexed = np.array([label_to_index_dict[label] for label in train_labels])\n",
        "train_labels_indexed = train_labels_indexed.reshape((train_labels_indexed.shape[0], -1))\n",
        "print(train_labels_indexed.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5569, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2nfY7GdBJ8d",
        "outputId": "61ead9cb-d214-458b-d3d2-dd821f345913"
      },
      "source": [
        "# Define a model and train\n",
        "input_layer = Input(shape=(384), name='input')\n",
        "hidden_layer = Dense(100, name='hidden')(input_layer)\n",
        "output_layer = Dense(2, activation='softmax', name='output')(hidden_layer)\n",
        "trained_model = Model(input_layer, output_layer, name='Sent-Transformer')\n",
        "print(trained_model.summary())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Sent-Transformer\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 384)]             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 100)               38500     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 38,702\n",
            "Trainable params: 38,702\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiG8QpolBp7_"
      },
      "source": [
        "# Compile the model\n",
        "trained_model.compile(optimizer='Adam',\n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoeodtGDDCGo",
        "outputId": "44b64e1d-744c-4dd0-d04a-d9b39e2271c0"
      },
      "source": [
        "# Train on the data\n",
        "trained_model.fit(train_sentence_vectors, train_labels_indexed, batch_size=8, epochs=30, validation_split=0.2)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "557/557 [==============================] - 2s 2ms/step - loss: 0.7106 - accuracy: 0.5664 - val_loss: 0.6459 - val_accuracy: 0.6490\n",
            "Epoch 2/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6475 - accuracy: 0.6275 - val_loss: 0.6322 - val_accuracy: 0.6499\n",
            "Epoch 3/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6286 - accuracy: 0.6431 - val_loss: 0.6383 - val_accuracy: 0.6364\n",
            "Epoch 4/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6158 - accuracy: 0.6628 - val_loss: 0.6297 - val_accuracy: 0.6526\n",
            "Epoch 5/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6147 - accuracy: 0.6699 - val_loss: 0.6357 - val_accuracy: 0.6490\n",
            "Epoch 6/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6083 - accuracy: 0.6657 - val_loss: 0.6467 - val_accuracy: 0.6158\n",
            "Epoch 7/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6174 - accuracy: 0.6585 - val_loss: 0.6278 - val_accuracy: 0.6580\n",
            "Epoch 8/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6203 - accuracy: 0.6600 - val_loss: 0.6386 - val_accuracy: 0.6463\n",
            "Epoch 9/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6096 - accuracy: 0.6733 - val_loss: 0.6291 - val_accuracy: 0.6634\n",
            "Epoch 10/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6083 - accuracy: 0.6607 - val_loss: 0.6384 - val_accuracy: 0.6472\n",
            "Epoch 11/30\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.6068 - accuracy: 0.6614 - val_loss: 0.6389 - val_accuracy: 0.6472\n",
            "Epoch 12/30\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.6105 - accuracy: 0.6753 - val_loss: 0.6319 - val_accuracy: 0.6535\n",
            "Epoch 13/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.6917 - val_loss: 0.6385 - val_accuracy: 0.6562\n",
            "Epoch 14/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.6705 - val_loss: 0.6301 - val_accuracy: 0.6634\n",
            "Epoch 15/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6094 - accuracy: 0.6696 - val_loss: 0.6307 - val_accuracy: 0.6607\n",
            "Epoch 16/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6026 - accuracy: 0.6720 - val_loss: 0.6293 - val_accuracy: 0.6517\n",
            "Epoch 17/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6012 - accuracy: 0.6795 - val_loss: 0.6350 - val_accuracy: 0.6517\n",
            "Epoch 18/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6756 - val_loss: 0.6340 - val_accuracy: 0.6418\n",
            "Epoch 19/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6068 - accuracy: 0.6647 - val_loss: 0.6334 - val_accuracy: 0.6652\n",
            "Epoch 20/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6836 - val_loss: 0.6260 - val_accuracy: 0.6688\n",
            "Epoch 21/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.6744 - val_loss: 0.6408 - val_accuracy: 0.6490\n",
            "Epoch 22/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.5997 - accuracy: 0.6793 - val_loss: 0.6286 - val_accuracy: 0.6571\n",
            "Epoch 23/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.5962 - accuracy: 0.6882 - val_loss: 0.6308 - val_accuracy: 0.6544\n",
            "Epoch 24/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.5995 - accuracy: 0.6778 - val_loss: 0.6333 - val_accuracy: 0.6634\n",
            "Epoch 25/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6780 - val_loss: 0.6270 - val_accuracy: 0.6580\n",
            "Epoch 26/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6069 - accuracy: 0.6588 - val_loss: 0.6342 - val_accuracy: 0.6625\n",
            "Epoch 27/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.6797 - val_loss: 0.6322 - val_accuracy: 0.6580\n",
            "Epoch 28/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.6830 - val_loss: 0.6385 - val_accuracy: 0.6598\n",
            "Epoch 29/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6829 - val_loss: 0.6361 - val_accuracy: 0.6553\n",
            "Epoch 30/30\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.6717 - val_loss: 0.6407 - val_accuracy: 0.6634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86e138af50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTQOuvGYDO1_",
        "outputId": "3c4bab29-0077-4504-c180-8898d028b883"
      },
      "source": [
        "# predict on test data\n",
        "test_sentence_vectors = create_sentence_vectors(test_data, sent_embed_model)\n",
        "predicted_sentiment_vectors = trained_model.predict(test_sentence_vectors)\n",
        "print(predicted_sentiment_vectors.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1393, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXtBtINFGXoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91759462-bb22-4582-84e4-1539eccb1ca3"
      },
      "source": [
        "# Evaluation\n",
        "predicted_sentiments = list()\n",
        "for pred in predicted_sentiment_vectors:\n",
        "  predicted_sentiments.append(index_to_label_dict[np.argmax(pred)])\n",
        "print(classification_report(test_labels, predicted_sentiments))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.60      0.64      0.62       697\n",
            "         pos       0.61      0.57      0.59       696\n",
            "\n",
            "    accuracy                           0.61      1393\n",
            "   macro avg       0.61      0.61      0.61      1393\n",
            "weighted avg       0.61      0.61      0.61      1393\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}